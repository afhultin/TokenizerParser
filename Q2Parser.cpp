#include <iostream>
#include <fstream>
using namespace std;

ifstream infp;

// Tokens names
enum Tokens {
    A_TOKEN, B_TOKEN, C_TOKEN, ENDFILE, UNKNOWN
};

const int SIZE = 100;
Tokens nextToken;
string lexeme;
char nextChar;

int errors = 0;      // counter for error messages
int line = 1;        // variable to keep track of the line number from the source code

/******************************************************/
/* Helping function to display the token as a string */
void prt(Tokens nt) {
    switch (nt) {
        case A_TOKEN: cout << "<A>"; break;
        case B_TOKEN: cout << "<B>"; break;
        case C_TOKEN: cout << "<C>"; break;
        case ENDFILE: cout << "<END>"; break;
        case UNKNOWN: cout << "<UNKNOWN>"; break;
        default: cout << "<Unspecified token>"; break;
    }

}

/********************************************/
/* errMsg - function to display the error message with the line number of the error detected. */
void errMsg(string msg) {
    cout << "Error at line: " << line << ": " << msg << endl;
    errors++;
}

/*****************************************************/
/* addChar - a function to add nextChar to lexeme */
void addChar(char nextChar) {
    lexeme += nextChar;
    if (lexeme.size() > 99) {
        errMsg("Lexeme size exceeds 100 characters");
        exit(0);
    }
}

char getChar() {
    char ch = infp.get();
    if (ch == '\n') {
        line++;
    }
    return ch;
}

/*****************************************************/
/* getNonBlank - a function to call getChar until it returns a non-whitespace character */
char getNonSpaceChar() {
    char ch = ' ';
    while (isspace(ch)) {
        ch = getChar();
    }
    return ch;
}


// lex - a simple lexical analyzer 
Tokens tokenizer() {
    lexeme = ""; // Clear the lexeme
    nextChar = getNonSpaceChar(); // Get the next non-space character

    if (nextChar == EOF) return ENDFILE; // End of file token

    // Check for 'a' token
    if (nextChar == 'a') {
        lexeme += nextChar; // Add character to lexeme
        nextChar = getChar(); // Get next character
        return A_TOKEN; // Return token for 'a'
    } 
    // Check for 'b' token
    else if (nextChar == 'b') {
        lexeme += nextChar; // Add character to lexeme
        nextChar = getChar(); // Get next character
        return B_TOKEN; // Return token for 'b'
    } 
    // Check for 'c' token
    else if (nextChar == 'c') {
        lexeme += nextChar; // Add character to lexeme
        nextChar = getChar(); // Get next character
        return C_TOKEN; // Return token for 'c'
    } 
    // Unknown character handling
    else {
        lexeme += nextChar; // Add unknown character to lexeme
        errMsg("Unknown character: ");
        nextChar = getChar(); // Get next character
        return UNKNOWN; // Return unknown token
    }
}


/******************************************* End of Lexical Analyzer (tokenizer) */
/******************************************* Start of Syntax Analyzer (parser) */

Tokens A() {
    if (nextToken == A_TOKEN) {
        nextToken = tokenizer(); // Get next token
        if (nextToken == A_TOKEN || nextToken == C_TOKEN || nextToken == B_TOKEN || nextToken == ENDFILE) {
            return A(); 
        }
        return nextToken; 
    }
    // Handle base case: single 'a'
    if (nextToken == A_TOKEN) {
        nextToken = tokenizer();
        return nextToken;
    }
    return ENDFILE;
}

/********************************************/

Tokens B() {
    if (nextToken == B_TOKEN) {
        nextToken = tokenizer(); // Get next token
        if (nextToken == B_TOKEN) {
            return B(); 
        }
        return nextToken; 
    }
    if (nextToken == B_TOKEN) {
        nextToken = tokenizer();
        return nextToken;
    }
    return ENDFILE;
}

/********************************************/

Tokens S() {
    if (nextToken == A_TOKEN) {
        nextToken = A(); // Parse <A>
        if (nextToken == C_TOKEN) {
            nextToken = tokenizer(); 
            return B(); 
        }
    }
    return A(); 
}
/**************************************************/
/* expr - Parses strings in the language generated by the rule: <expr> -> <term> {(+ | -) <term>} */

/******************************************* End of Syntax Analyzer (parser) */
/******************************************************/
/* main driver */
int main() {
    infp.open("prg.in"); 
    if (!infp) {
        cout << "ERROR OPENING FILE" << endl;
        errors++;
    }
    else {
        nextToken = tokenizer(); // Get the first token
    do {
        if (nextToken == A_TOKEN || nextToken == B_TOKEN || nextToken == C_TOKEN) {
            nextToken = S(); // Start parsing
        } else {
            errMsg("Invalid start of statement");
            nextToken = ENDFILE;
        }
    } while (nextToken != ENDFILE);
    cout << "Total number of errors: " << errors << endl;
    return 0;
}
}